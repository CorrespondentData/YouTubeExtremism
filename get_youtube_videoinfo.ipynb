{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the YouTube information bubbles\n",
    "\n",
    "This notebook helps you get all the relevant information to explore information bubbles on YouTube. The idea is that you take a list of keywords, videos or channels, find related videos or channels, get all the metadata, comments and videotranscripts you need and use natural language processing techniques to explore and analyze the data. This notebook uses Python3. There is a similar script available for the R language. \n",
    "\n",
    "### Here's what still needs to be done:\n",
    "\n",
    "1. Implement a search functionality so you can build a seed list from keywords, videos or channels. Currently were are using the [YouTubeDataTool](https://tools.digitalmethods.net/netvizz/youtube/).\n",
    "2. All code needs to be more pythonic. \n",
    "3. Filtering options need to be added before compiling the final channel seeds list. \n",
    "4. If the channel seed list is large, we need multithreading options to help with data collection.\n",
    "5. We need to find more clever ways to work around the throttling of the YouTube API.\n",
    "6. We need download buffers. If an error is thrown, or if we add some data to the seed list, previous downloaded data should be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import unicode_literals\n",
    "import youtube_dl\n",
    "import codecs\n",
    "import webvtt\n",
    "import glob\n",
    "import csv\n",
    "import requests\n",
    "import os.path\n",
    "import config\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a config.py file with these constants\n",
    "\n",
    "YOUTUBE_API_SERVICE_NAME = config.YOUTUBE_API_SERVICE_NAME\n",
    "YOUTUBE_API_VERSION = config.YOUTUBE_API_VERSION\n",
    "DEVELOPER_KEY = config.DEVELOPER_KEY\n",
    "PATH_TEMP_RIGHT = config.PATH_TEMP_RIGHT\n",
    "PATH_TEMP_LEFT = config.PATH_TEMP_LEFT\n",
    "\n",
    "#uncomment which bubble you want to investigate\n",
    "\n",
    "#seeds = PATH_TEMP_RIGHT + 'right_seeds.csv' #if you want to investigate the right bubble\n",
    "seeds = PATH_TEMP_LEFT + 'lefty_seeds_v2.csv' #if you want to investigate the left bubble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_seeds = pd.read_csv(seeds, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(channel_id):\n",
    "    '''Queries the youtube API and \n",
    "    gets a json in return'''\n",
    "        \n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "                    developerKey=DEVELOPER_KEY)\n",
    "    \n",
    "    response = youtube.channels().list(\n",
    "    part = 'snippet,contentDetails,topicDetails,statistics,brandingSettings',\n",
    "    id = channel_id\n",
    "    ).execute()\n",
    "    #print('getting channel info for %s' % (channel_id))\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_channel_data(response):\n",
    "    '''Extracts the needed variables \n",
    "    from the returned json'''\n",
    "    \n",
    "    for channel in response['items']:\n",
    "        channel_id = channel['id']\n",
    "        channel_title = channel['snippet']['title']\n",
    "        channel_description = channel['snippet']['description']\n",
    "        try: #many channels do not set a language so we need to catch the exception\n",
    "            channel_default_language = channel['snippet']['defaultLanguage']\n",
    "        except:\n",
    "            channel_default_language = 'not set'\n",
    "        try:\n",
    "            channel_country = channel['snippet']['country']\n",
    "        except:\n",
    "            channel_country = 'not set'\n",
    "        channel_viewcount = channel['statistics']['viewCount']\n",
    "        channel_commentcount = channel['statistics']['commentCount']\n",
    "        channel_subscribercount = channel['statistics']['subscriberCount']\n",
    "        channel_videocount = channel['statistics']['videoCount']\n",
    "        try:\n",
    "            channel_topic_ids = channel['topicDetails']['topicIds']\n",
    "        except:\n",
    "            channel_topic_ids = 'not set'\n",
    "        try:\n",
    "            channel_topic_categories = channel['topicDetails']['topicCategories']\n",
    "        except:\n",
    "            channel_topic_categories = 'not set'\n",
    "            \n",
    "        try:\n",
    "            channel_branding_keywords = channel['brandingSettings']['channel']['keywords']\n",
    "        except:\n",
    "            channel_branding_keywords = 'not set'\n",
    "        \n",
    "        return (channel_id,\n",
    "                channel_title,\n",
    "                channel_description,\n",
    "                channel_default_language,\n",
    "                channel_country,\n",
    "                channel_viewcount,\n",
    "                channel_commentcount,\n",
    "                channel_subscribercount,\n",
    "                channel_videocount,\n",
    "                channel_topic_ids,\n",
    "                channel_topic_categories,\n",
    "                channel_branding_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to a file\n",
    "\n",
    "channels = PATH_TEMP_LEFT + 'channels_left.csv'\n",
    "count = -1 # if there is an error, it's easier to find the index position from where to continue\n",
    "\n",
    "with open(channels, \"a\") as csvFile:\n",
    "    fieldnames = ['channel_id',\n",
    "                  'channel_title',\n",
    "                  'channel_description',\n",
    "                  'channel_default_language',\n",
    "                  'channel_country',\n",
    "                  'channel_viewcount',\n",
    "                  'channel_commentcount',\n",
    "                  'channel_subscribercount',\n",
    "                  'channel_videocount',\n",
    "                  'channel_topic_ids',\n",
    "                  'channel_topic_categories',\n",
    "                  'channel_branding_keywords'                                 \n",
    "                 ]\n",
    "\n",
    "    writer = csv.DictWriter(csvFile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for channel in channel_seeds['Id']:\n",
    "        try:\n",
    "            response = get_channels(channel)\n",
    "            variabelen = get_channel_data(response)\n",
    "            (channel_id,\n",
    "            channel_title,\n",
    "            channel_description,\n",
    "            channel_default_language,\n",
    "            channel_country,\n",
    "            channel_viewcount,\n",
    "            channel_commentcount,\n",
    "            channel_subscribercount,\n",
    "            channel_videocount,\n",
    "            channel_topic_ids,\n",
    "            channel_topic_categories,\n",
    "            channel_branding_keywords) = variabelen\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        writer.writerow({'channel_id': channel_id, \n",
    "                         'channel_title': channel_title, \n",
    "                         'channel_description': channel_description, \n",
    "                         'channel_default_language': channel_default_language, \n",
    "                         'channel_country': channel_country,\n",
    "                         'channel_viewcount': channel_viewcount,\n",
    "                         'channel_commentcount': channel_commentcount,\n",
    "                         'channel_subscribercount': channel_subscribercount,\n",
    "                         'channel_videocount': channel_videocount,\n",
    "                         'channel_topic_ids': channel_topic_ids,\n",
    "                         'channel_topic_categories': channel_topic_categories,\n",
    "                         'channel_branding_keywords': channel_branding_keywords  \n",
    "                        })\n",
    "        count += 1\n",
    "                         \n",
    "        print('wrote data for ' + channel_title + ' and index is ' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter channel data\n",
    "\n",
    "Filter the channel data to get a relevant seed list. It's better to do some extra work here, it saves you a lot of work (and API calls) later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_seeds = pd.read_csv(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(channel):\n",
    "    '''Takes a channel_id and finds \n",
    "    the first 50 videos'''\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "                    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "    response = youtube.search().list(\n",
    "    channelId = channel,\n",
    "    type = 'video',\n",
    "    part ='snippet',\n",
    "    maxResults = 50,\n",
    "    ).execute()\n",
    "    print('getting videos for ' + channel)\n",
    "    return response\n",
    "\n",
    "def get_more_videos(channel):\n",
    "    '''Takes a channel_id and looks for\n",
    "    the next page in the result list.'''\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "                    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "    response = youtube.search().list(\n",
    "    channelId = channel,\n",
    "    type = 'video',\n",
    "    part ='snippet',\n",
    "    maxResults = 50,\n",
    "    pageToken = nextPageToken\n",
    "    ).execute()\n",
    "    print('getting more pages of ' + channel)\n",
    "\n",
    "    return response\n",
    "\n",
    "def get_video_metadata(video_id):\n",
    "    '''Takes a video_id and gets\n",
    "    the associated metadata'''\n",
    "    \n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "                    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "    response = youtube.videos().list(\n",
    "        part = 'snippet,contentDetails,statistics',\n",
    "        id = video_id\n",
    "        ).execute()\n",
    "    \n",
    "    return response\n",
    "\n",
    "def write_video_data_to_file(response, video_file):\n",
    "    '''Write the video data to a file'''\n",
    "    \n",
    "    with open(video_file, \"a\") as csvFile:\n",
    "        fieldnames = ['video_published', \n",
    "                      'video_id', \n",
    "                      'channel_id', \n",
    "                      'video_title', \n",
    "                      'video_description',\n",
    "                      'channel_title',\n",
    "                      'video_category_id',\n",
    "                      'video_tags',\n",
    "                      'video_duration',\n",
    "                      'video_view_count',\n",
    "                      'video_comment_count',\n",
    "                      'video_likes_count',\n",
    "                      'video_dislikes_count',\n",
    "                      'video_topic_ids',\n",
    "                      'video_topic_categories'\n",
    "                     ]\n",
    "    \n",
    "        writer = csv.DictWriter(csvFile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "    \n",
    "    \n",
    "        for video in response['items']:\n",
    "\n",
    "            video_published = video['snippet']['publishedAt']\n",
    "            video_id = video['id']['videoId']\n",
    "            channel_id = video['snippet']['channelId']\n",
    "            video_title = video['snippet']['title']\n",
    "            video_description = video['snippet']['description']\n",
    "            channel_title = video['snippet']['channelTitle']\n",
    "            try:\n",
    "                video_category_id = video['snippet']['categoryId']\n",
    "            except:\n",
    "                video_category_id = 'not set'\n",
    "            try:\n",
    "                video_tags = video['snippet']['tags']\n",
    "            except:\n",
    "                video_tags = 'not set'\n",
    "\n",
    "            video_metadata = get_video_metadata(video_id)\n",
    "\n",
    "            for metadata in video_metadata['items']:\n",
    "                print('getting metadata for ' + video_title)\n",
    "\n",
    "\n",
    "                video_duration = metadata['contentDetails']['duration']\n",
    "                video_view_count = metadata['statistics']['viewCount']\n",
    "                try:\n",
    "                    video_comment_count = metadata['statistics']['commentCount']\n",
    "                except:\n",
    "                    video_comment_count = 0\n",
    "\n",
    "                try:\n",
    "                    video_likes_count = metadata['statistics']['likeCount']\n",
    "                except:\n",
    "                    video_likes_count = 0\n",
    "\n",
    "                try:\n",
    "                    video_dislikes_count = metadata['statistics']['dislikeCount']\n",
    "                except:\n",
    "                    video_dislikes_count = 0\n",
    "\n",
    "                try:\n",
    "                    video_topic_ids = metadata['topicDetails']['topicIds']\n",
    "                except:\n",
    "                    video_topic_ids = 'not set'\n",
    "                try:\n",
    "                    video_topic_categories = metadata['topicDetails']['topicCategories']\n",
    "                except:\n",
    "                    video_topic_categories = 'not set'\n",
    "                try:\n",
    "                    video_category_id = metadata['snippet']['categoryId']\n",
    "                except:\n",
    "                    video_category_id = 'not set'\n",
    "                try:\n",
    "                    video_tags = metadata['snippet']['tags']\n",
    "                except:\n",
    "                    video_tags = 'not set'\n",
    "\n",
    "                writer.writerow({'video_published': video_published,\n",
    "                                 'video_id': video_id,\n",
    "                                 'channel_id': channel_id,\n",
    "                                 'video_title': video_title,\n",
    "                                 'video_description': video_description,\n",
    "                                 'channel_title': channel_title,\n",
    "                                 'video_category_id':video_category_id,\n",
    "                                 'video_tags': video_tags,\n",
    "                                 'video_duration': video_duration,\n",
    "                                 'video_view_count': video_view_count,\n",
    "                                 'video_comment_count': video_comment_count,\n",
    "                                 'video_likes_count': video_likes_count,\n",
    "                                 'video_dislikes_count': video_dislikes_count,\n",
    "                                 'video_topic_ids': video_topic_ids,\n",
    "                                 'video_topic_categories': video_topic_categories\n",
    "                                })\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#channels = pd.read_csv(config.PATH_TEMP_RIGHT + 'channels.csv')\n",
    "video_file = PATH_TEMP_RIGHT + 'video_file_test.csv'\n",
    "\n",
    "for channel in sample['Id']:\n",
    "    response = get_videos(channel)\n",
    "    nextPageToken = response.get('nextPageToken', None)\n",
    "    write_video_data_to_file(response, video_file)\n",
    "    while nextPageToken:\n",
    "        response = get_more_videos(channel)\n",
    "        nextPageToken = response.get('nextPageToken', None)\n",
    "        print('getting more videos for ' + channel)\n",
    "        write_video_data_to_file(response, video_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(videoId):\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "                    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "    response = youtube.commentThreads().list(\n",
    "    videoId = videoId,\n",
    "    part ='snippet,replies'\n",
    "    ).execute()\n",
    "\n",
    "    return response\n",
    "\n",
    "def get_more_comments(videoId):\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "                    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "    response = youtube.commentThreads().list(\n",
    "    videoId = videoId,\n",
    "    pageToken = nextPageToken,\n",
    "    part ='snippet,replies'\n",
    "    ).execute()\n",
    "\n",
    "    return response\n",
    "\n",
    "def write_comments(response, comments_file):\n",
    "    with open(comments_file, 'a') as csvFile:\n",
    "            header = ['video_id', \n",
    "                      'comment_id', \n",
    "                      'author_display_name', \n",
    "                      'author_channel_url', \n",
    "                      'author_channel_id', \n",
    "                      'comment_text', \n",
    "                      'comment_like_count', \n",
    "                      'comment_dislike_count']\n",
    "            writer = csv.DictWriter(csvFile, fieldnames=header)\n",
    "            writer.writeheader()\n",
    "            for data in response['items']:\n",
    "                comment_id = data['id']\n",
    "                video_id = data['snippet']['videoId']\n",
    "                author_display_name = data['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
    "                author_channel_url =data['snippet']['topLevelComment']['snippet']['authorChannelUrl']\n",
    "                author_channel_id = data['snippetauthorChannelId']['topLevelComment']['snippet']['authorChannelId']['value']\n",
    "                comment_text = data['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "                comment_likes_count = data['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "                comment_dislikes_count = data['snippet']['topLevelComment']['snippet']['disLikeCount']\n",
    "                comment_time = data['snippet']['topLevelComment']['snippet']['publishedAt']\n",
    "                \n",
    "                \n",
    "                writer.writerow(({'video_id': video_id, \n",
    "                                  'comment_id': comment_id, \n",
    "                                  'author_display_name': author_display_name, \n",
    "                                  'author_channel_url': author_channel_url, \n",
    "                                  'author_channel_id': author_channeld_id, \n",
    "                                  'comment_text': comment_text,\n",
    "                                  'comment_like_count': comment_likes_count,\n",
    "                                  'comment_dislike_count': comment_dislike_count,\n",
    "                                  'comment_time': comment_time\n",
    "                                 }))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_file = 'comments.csv'\\\n",
    "vidlist = ''\n",
    "\n",
    "for videoId in vidlist['videoId']:\n",
    "    try:\n",
    "        response = get_comments(videoId)\n",
    "        nextPageToken = response.get('nextPageToken', None)\n",
    "        write_comments(response, comments_file)\n",
    "        while nextPageToken:\n",
    "            response = get_more_comments(videoId)\n",
    "            nextPageToken = response.get('nextPageToken', None)\n",
    "            write_comments(response, comments_file)\n",
    "    except:\n",
    "        continue\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: get related channels\n",
    "\n",
    "def get_recommendations(video_id):\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "                    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "    response = youtube.search().list(\n",
    "    #videoId = video_id,\n",
    "    part ='snippet',\n",
    "    type = 'video',\n",
    "    relatedToVideoId = video_id,\n",
    "    maxResults = 50\n",
    "    ).execute()\n",
    "\n",
    "    return response\n",
    "\n",
    "def write_recommendations(response, recommendations_file, videoId):\n",
    "    for data in response['items']:\n",
    "        targetVideoId = data['id']['videoId']\n",
    "        publishedAt = data['snippet']['publishedAt']\n",
    "        channelId = data['snippet']['channelId']\n",
    "        title = data['snippet']['title']\n",
    "        description = data['snippet']['description']\n",
    "        \n",
    "        \n",
    "        with open(recommendations_file, 'a') as csvFile:\n",
    "            header = ['videoId', 'targetVideoId', 'publishedAt', 'channelId', 'title', 'description']\n",
    "            writer = csv.DictWriter(csvFile, fieldnames=header)\n",
    "            writer.writerow(({'videoId': videoId, \n",
    "                              'targetVideoId': targetVideoId, \n",
    "                              'publishedAt': publishedAt, \n",
    "                              'channelId': channelId, \n",
    "                              'title': title, \n",
    "                              'description': description \n",
    "                              }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = '/home/dim/Documents/projecten/extremisme/youtube/data/temp/bubble/videos.csv'\n",
    "\n",
    "columns=['videoId', 'publishedAt','videoTitle', 'channelId', 'channelTitle']\n",
    "vidlist = pd.read_csv(video_file, header=None, names=columns)\n",
    "\n",
    "vidlist = vidlist[31906:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recommendations_file = 'recommendations.csv'\n",
    "\n",
    "for videoId in vidlist['videoId']:\n",
    "    response = get_recommendations(videoId)\n",
    "    write_recommendations(response, recommendations_file, videoId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recos = pd.read_csv('recommendations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recos.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydl_opts = {\n",
    "    'writeautomaticsub': True,\n",
    "    'skip_download': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    for video in sample['videoId']:\n",
    "        video = 'https://www.youtube.com/watch?v=' + str(video)\n",
    "        ydl.download([video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoId = []\n",
    "words = []\n",
    "transcript = []\n",
    "\n",
    "for filename in glob.glob('~/Documents/projecten/extremisme/youtube/data/temp/bubble/*.vtt'):\n",
    "    ids = os.path.basename(filename)\n",
    "    ids = ids[-18:-7]\n",
    "    videoId.append(ids)\n",
    "    try:\n",
    "        for caption in webvtt.read(filename):\n",
    "            words.append(caption.text)\n",
    "        transcript.append(words)\n",
    "    except:\n",
    "        pass\n",
    "    words = []\n",
    "    \n",
    "file_exists = os.path.isfile('captions.csv')\n",
    "\n",
    "with open('captions.csv', 'w') as csvfile:\n",
    "    header = ['videoId', 'transcript']\n",
    "    writer=csv.writer(csvfile, delimiter=',', fieldnames=header)\n",
    "    \n",
    "    if not file_exists:\n",
    "                writer.writeheader()\n",
    "    writer.writerows(zip(videoId, transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get language info and translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second for videoDescription\n",
    "#for authentication see: https://cloud.google.com/translate/docs/quickstart-client-libraries\n",
    "\n",
    "\n",
    "lang = []\n",
    "trans = []\n",
    "conf = []\n",
    "target = 'en'\n",
    "\n",
    "for text in videos_sample['videoDescription']:\n",
    "    translation = translate_client(text, target_language=target)\n",
    "    language = translate_client.detect_language(text)\n",
    "    \n",
    "    language_result = language['language']\n",
    "    confidence_result = language['confidence']\n",
    "    translation_result = translation['translatedText']\n",
    "    language = translation['detectedSourceLanguage']\n",
    "    \n",
    "    lang.append(language_result)\n",
    "    conf.append(confidence_result)\n",
    "    trans.append(translation_result)\n",
    "    \n",
    "videos_sample['language_videoDescription'] = lang\n",
    "videos_sample['language_videoDescription_confidence'] = conf\n",
    "videos_sample['english_videoDescription'] = trans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_api",
   "language": "python",
   "name": "youtube_api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
